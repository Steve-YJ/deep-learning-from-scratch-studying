{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹ ê²½ë§\n",
    "\n",
    "Reference: https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹ ê²½ë§ì€ <code>torch.nn</code> íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•  ìˆ˜ ìˆë‹¤.<br/>\n",
    "ì§€ê¸ˆê¹Œì§€ <code>autograd</code>ë¥¼ ì‚´í´ë´¤ë‹¤. \n",
    "\n",
    "<code>nn</code>ì€ ëª¨ë¸ì„ ì •ì˜í•˜ê³  ë¯¸ë¶„í•˜ëŠ” ë° <code>autograd</code>ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "<code>nn.Module</code>ì€ ê³„ì¸µ(Layer)ê³¼ <code>output</code>ì„ ë°˜í™˜í•˜ëŠ” <code>forward(input)</code> ë©”ì„œë“œë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ˜„ ìš°ë¦¬ê°€ ì´ì „ ì¥ì—ì„œ ë°°ì› ë˜ <code>autograd</code>(ìë™ë¯¸ë¶„) íŒ¨í‚¤ì§€ê°€ <code>nn</code> ëª¨ë“ˆê³¼ ë§Œë‚˜ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì•Œì•„ë³´ì<br>\n",
    "ğŸ˜„ ê·¸ë¦¬ê³  <code>nn</code>íŒ¨í‚¤ì§€ë„ ìƒ…ìƒ…íˆ íŒŒí—¤ì³ë³´ì!(Torch Packageë¥¼ ë‚±ë‚±ì´ íŒŒí—¤ì¹˜ê³ ì™”ë‹¤! ì´ì œ í•™ìŠµë§Œ ì˜ í•˜ë©´ ëœë‹¤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ëŠ˜ì˜ ì˜ˆì œëŠ” ìˆ«ì ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‹ ê²½ë§ì´ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./LeNet-5 Architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 Architecture as Published in the original paper<a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:\n",
    "\n",
    "https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì— ë³´ì´ëŠ” LeNetì€ ê°„ë‹¨í•œ ìˆœì „íŒŒ ë„¤íŠ¸ì›Œí¬(Feed-forward network)ì´ë‹¤.\n",
    "\n",
    "ì…ë ¥(input)ì„ ë°›ì•„ ì—¬ëŸ¬ ê³„ì¸µì— ì°¨ë¡€ë¡œ ì „ë‹¬í•œ í›„, ìµœì¢… ì¶œë ¥(output)ì„ ì œê³µí•œë‹¤.\n",
    "\n",
    "ì‹ ê²½ë§ì˜ ì¼ë°˜ì ì¸ í•™ìŠµê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.<br/>\n",
    "* í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œ ë³€ìˆ˜(ë˜ëŠ” ê°€ì¤‘ì¹˜(weight)ë¥¼ ê°–ëŠ” ì‹ ê²½ë§ì„ ì •ì˜í•œë‹¤.\n",
    "* ë°ì´í„°ì…‹(dataset)ì…ë ¥ì„ ë°˜ë³µí•œë‹¤.\n",
    "* ì…ë ¥ì„ ì‹ ê²½ë§ì—ì„œ ì „íŒŒ(process)í•œë‹¤.\n",
    "* ì†ì‹¤(loss: ì¶œë ¥ì´ ì •ë‹µìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€)ì„ ê³„ì‚°í•œë‹¤.\n",
    "* ë³€í™”ë„(gradient)ë¥¼ ì‹ ê²½ë§ì˜ ë§¤ê°œë³€ìˆ˜ë“¤ì— ì—­ìœ¼ë¡œ ì „íŒŒí•œë‹¤. (Backpropagation)\n",
    "* ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê°„ë‹¨í•œ ê·œì¹™ì„ ì‚¬ìš©í•œë‹¤.<br/>\n",
    "<code>ì—…ë°ì´íŠ¸ëœ ê°€ì¤‘ì¹˜(weight) = ê°€ì¤‘ì¹˜(weight) - í•™ìŠµë¥ (learning rate) * ë³€í™”ë„(gradient)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W1 = W0 - Î·*(df/dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì‹ ê²½ë§ ì •ì˜í•˜ê¸°\n",
    "ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ì‹ ê²½ë§ì„ ì •ì˜í•´ë³´ë„ë¡ í•˜ì<br/>\n",
    "**ì£¼ì„ì˜ Question(Q)ì„ ì£¼ëª©í•´ë³´ì!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module): # nn.Module ëª¨ë“  ì‹ ê²½ë§ ëª¨ë“ˆì˜ ê¸°ë³¸ì´ ë˜ëŠ” í´ë˜ìŠ¤\n",
    "                      # ê° ì¸µê³¼ í•¨ìˆ˜ ë“± ì‹ ê²½ë§ì˜ êµ¬ì„±ìš”ì†Œë¥¼ ì´ í´ë˜ìŠ¤ ì•ˆì—ì„œ ì •ì˜í•œë‹¤.\n",
    "        \n",
    "    def __init__(self):  # ì´ˆê¸°í™” í•¨ìˆ˜   \n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        # (kernelê³¼ filterëŠ” ê°™ë‹¤) ì¦‰, filter sizeëŠ” 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  # ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, í•„í„°ì˜ í¬ê¸°\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3) # ë§ˆì°¬ê°€ì§€ ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, í•„í„°ì˜ í¬ê¸°    \n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # Q1. ë§¤ê°œë³€ìˆ˜ ê°’ì€ ì–´ë–»ê²Œ ê³„ì‚°í•´ì•¼í• ê¹Œ?\n",
    "                                               # 6*6 from image dimension? -20.02.20.Thur pm 2:00-\n",
    "                                               # image dimensionì€ ì–´ë–»ê²Œ êµ¬í•˜ì§€? -20.02.20.Thur pm 8:05-\n",
    "                                               # https://discuss.pytorch.org/t/linear-layer-input-neurons-number-calculation-after-conv2d/28659\n",
    "                                               # Set the number of in_features for the first linear layer to (outputchanel * size of image)\n",
    "                                               # output_chanel_num * height * width\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "# Affine Operationì—ì„œ Linear ê³„ì¸µì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ì–´ë–»ê²Œ ì •í•´ì§€ëŠ”ê±´ê°€? -20.02.20.Thur pm 7:49\n",
    "# ì—¬ì „íˆ ë¯¸ìŠ¤í…Œë¦¬ë‹¤(20.02.21.Fri.pm 12:22)... Torch Docì„ ë’¤ì ¸ë³´ì\n",
    "# nn.Linear()í•¨ìˆ˜ì˜ ì²« ë²—ì§¸ ì¸ìì—ëŠ” input sampleì˜ sizeê°€ ë“¤ì–´ê°„ë‹¤.\n",
    "# ë‘ ë²ˆì§¸ ì¸ìì—ëŠ” output sampleì˜ sizeê°€ ë“¤ì–´ê°„ë‹¤.\n",
    "# clas:: torch.nn.Linear(in_features, out_features, bias=True)\n",
    "# ë³¸ ì˜ˆì œì—ì„œëŠ” ì²« ì¸ìë¡œ 16 * 6 * 6ì˜ ê°’ì„ ì¸ìë¡œ ë°›ëŠ”ë° \n",
    "# ì´ëŠ” Conv2 ê³„ì¸µì„ ì§€ë‚œ ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ê°€ 16, input_imageì˜ dimensionì´ 6*6ì´ê¸° ë•Œë¬¸ì´ë‹¤.\n",
    "# ì •ë¦¬í•˜ë©´ self1.fc1 = nn.Linear(16 * 6 * 6, 120)ì´ ëœë‹¤.\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>forward</code>í•¨ìˆ˜ë§Œ ì •ì˜í•˜ê³  ë‚˜ë©´, (ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ëŠ”) <code>backward</code>í•¨ìˆ˜ëŠ” <code>autograd</code>ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ì •ì˜ëœë‹¤. <code>forward</code>í•¨ìˆ˜ì—ì„œëŠ” ì–´ë– í•œ Tensor ì—°ì‚°ì„ ì‚¬ìš©í•´ë„ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì€ <code>net.parameters()</code>ì— ì˜í•´ ë°˜í™˜ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„ì˜ì˜ 32x32 ì…ë ¥ê°’ì„ ë„£ì–´ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**<br>\n",
    "ì´ ì‹ ê²½ë§(LeNet)ì˜ ì˜ˆìƒë˜ëŠ” ì…ë ¥ í¬ê¸°ëŠ” 32x32ì´ë‹¤. ì´ ì‹ ê²½ë§ì— MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”, ë°ì´í„°ì…‹ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 32x32ë¡œ ë³€ê²½í•´ì•¼ í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0811, -0.1157, -0.0431, -0.0696,  0.1271,  0.0314, -0.0562,  0.0463,\n",
      "          0.0287, -0.1436]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ ë²„í¼(gradient buffer)ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê³„ì† ì§„í–‰í•˜ê¸° ì „ì—, ì§€ê¸ˆê¹Œì§€ ì‚´í´ë´¤ë˜ ê²ƒë“¤ì„ ë‹¤ì‹œ í•œë²ˆ ìš”ì•½í•´ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ìš”ì•½**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <code>torch.Tensor</code> - <code>backward()</code>ì™€ ê°™ì€ autograd ì—°ì‚°ì„ ì§€ì›í•˜ëŠ” ë‹¤ì°¨ì› ë°°ì—´ì´ë‹¤. ë˜í•œ tensorì— ëŒ€í•œ ë³€í™”ë„(gradient)ë¥¼ ê°–ê³  ìˆë‹¤.\n",
    "\n",
    "* <code>nn.Module</code> - ì‹ ê²½ë§ ëª¨ë“ˆ. ë§¤ê°œë³€ìˆ˜ë¥¼ ìº¡ìŠí™”(encapsulation)í•˜ëŠ” ê°„í¸í•œ ë°©ë²•ìœ¼ë¡œ, GPUë¡œ ì´ë™, ë‚´ë³´ë‚´ê¸°(exporting), ë¶ˆëŸ¬ì˜¤ê¸°(loading)ë“±ì˜ ì‘ì—…ì„ ìœ„í•œ í—¬í¼(helper)ë¥¼ ì œê³µí•œë‹¤.\n",
    "\n",
    "* <code>nn.Parameter</code> - Tensorì˜ í•œ ì¢…ë¥˜ë¡œ, <code>Module</code>ì— ì†ì„±ìœ¼ë¡œ í• ë‹¹ë  ë•Œ ìë™ìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ë¡œ ë“±ë¡ëœë‹¤.\n",
    "\n",
    "* <code>autograd.Function</code> - autograd ì—°ì‚°ì˜ ì „ë°©í–¥ê³¼ ì—­ë°©í–¥ì •ì˜ë¥¼ êµ¬í˜„í•œë‹¤. ëª¨ë“  <code>Tensor</code>ì—°ì‚°ì€ í•˜ë‚˜ ì´ìƒì˜ <code>Function</code>ë…¸ë“œë¥¼ ìƒì„±í•˜ë©°, ê° ë…¸ë“œëŠ” <code>Tensor</code>ë¥¼ ìƒì„±í•˜ê³  ì´ë ¥(history)ì„ ë¶€í˜¸í™” í•˜ëŠ” í•¨ìˆ˜ë“¤ê³¼ ì—°ê²°í•˜ê³  ìˆë‹¤.\n",
    "\n",
    "ğŸ‘‰ğŸ» ëª¨ë“  Tensor ì—°ì‚°ì€ ì ì–´ë„ í•˜ë‚˜ì˜ Function nodeë¥¼ ìƒì„±í•˜ëŠ”ë° Function NodeëŠ” í…ì„œë¥¼ ìƒì„±í•œ í•¨ìˆ˜ì™€ ì—°ê²°ëœë‹¤.<br/>\n",
    "ğŸ‘‰ğŸ» autograd packageë¥¼ ì‚¬ìš©í•´ì„œ ì§ì ‘ í™•ì¸í•´ë³¸ë‹¤ë©´ ë³´ë‹¤ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆê²Œ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤**\n",
    "* ì‹ ê²½ë§ì„ ì •ì˜í•˜ëŠ” ê²ƒ\n",
    "* ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  <code>backward</code>ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ë” ì‚´í´ë³¼ë‚´ìš©ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤**\n",
    "* ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” ê²ƒ\n",
    "* ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ì˜ì–´ìë£Œ: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
