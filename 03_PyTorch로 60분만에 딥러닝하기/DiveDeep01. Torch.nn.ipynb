{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiveDeep into PyTorch\n",
    "Tutorialì„ ë”°ë¼í•˜ë©´ì„œ ë°œê²¬í•œ ê¶ê¸ˆì¦ì„ í•´ì†Œí•˜ê³¼ í•´ê²°í•˜ì§€ ëª»í•œ ë¬¸ì œë“¤ì„ í•´ê²°í•˜ëŠ” ì‹œê°„\n",
    "\n",
    "PyTorch Docì„ í†µí•´ í•˜ë‚˜í•˜ë‚˜ ë…íŒŒí•´ ë‚˜ê°€ì!\n",
    "\n",
    "Torch Documentation: https://pytorch.org/docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤” Q1. How to calculate the output size after Conv2d in PyTorch? -20.02.20.Thur pm4:20-<br>\n",
    "Link: http://bitly.kr/bbjdFjRp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Complete! - 20.02.20.Thur pm5:23\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤” Q2. Linear layer inpt neurons number calculation after conv2d -20.02.20.Thur pm 4:20-<br>\n",
    "Link: http://bitly.kr/bH5wNhWr\n",
    "\n",
    "\n",
    "ğŸ™Š ì„¤ëª…ì´ ëŒ€ë°•ì´ë‹¤. <br/>\n",
    "ë‹¤ì‹œ Torch NN ì˜ˆì œë¡œ ëŒì•„ê°€ì! -20.02.20.Thur pm 6:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Convolutional Layer](#ConvLayer)\n",
    "    * [Conv2d](#Conv2d)\n",
    "    \n",
    "* [Linear](#Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown Reference:\n",
    "# https://www.kaggle.com/general/24692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Torch.nn\n",
    "Ref: https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module\n",
    "CLASS<code>torch.nn.Module</code><br>\n",
    "\n",
    "Base class for all neural network modules.\n",
    "\n",
    "Your models should also subclass this class.\n",
    "\n",
    "Modules can also contain other Modules, allowwing to nest them in a tree structure. you can assign the submodules as regular attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class<code>torch.nn.Linear(in_features, out_features, bias=True)</code>ë¥¼ ê³µë¶€í•˜ë˜ ì¤‘... nn.Lienar()ëª¨ë“ˆì— ëŒ€í•œ ì´í•´ê°€ ì˜ ë˜ì§€ ì•Šì•„ ë‹¤ì‹œ nn ëª¨ë“ˆë¡œ ëŒì•„ì™”ë‹¤. -20.02.21.Fri pm 3:25-\n",
    "\n",
    "ğŸ‘¨â€ğŸ”§ ë‹¤ì‹œ ì²˜ìŒë¶€í„° ì°¨ê·¼ì°¨ê·¼íˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜ˆì œë¡œ ë°°ìš°ëŠ” íŒŒì´í† ì¹˜<br>\n",
    "reference: https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>nn</code>íŒ¨í‚¤ì§€ëŠ” ì‹ ê²½ë§ ê³„ì¸µ(layer)ë“¤ê³¼ ê±°ì˜ ë™ì¼í•œ **Module**ì˜ ì§‘í•©ì„ ì •ì˜í•œë‹¤. \n",
    "\n",
    "Moduleì€ ì…ë ¥ Tensorë¥¼ ë°›ê³  ì¶œë ¥ Tensorë¥¼ ê³„ì‚°í•˜ëŠ” í•œí¸, í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°–ëŠ” Tensor ê°™ì€ ë‚´ë¶€ ìƒëŒ€(internal state)ë¥¼ ê°–ëŠ”ë‹¤. <code>nn</code>íŒ¨í‚¤ì§€ëŠ” ë˜í•œ ì‹ ê²½ë§ì„ í•™ìŠµì‹œí‚¬ ë•Œ ì£¼ë¡œ ì‚¬ìš©í•˜ëŠ” ìœ ìš©í•œ ì†ì‹¤ í•¨ìˆ˜ë“¤ë„ ì •ì˜í•˜ê³  ìˆë‹¤.\n",
    "\n",
    "<code>nn</code>íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ 2ê³„ì¸µ ì‹ ê²½ë§ì„ êµ¬ì„±í•´ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 698.82275390625\n",
      "199 648.9466552734375\n",
      "299 605.8740844726562\n",
      "399 568.2747192382812\n",
      "499 534.7984619140625\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "# Nì€ ë°°ì¹˜ í¬ê¸°ì´ë©°, D_inì€ ì…ë ¥ì˜ ì°¨ì›ì´ë‹¤.(Dimension Input?)\n",
    "# HëŠ” ì€ë‹‰ì¸µì˜ ì°¨ì›ì´ë©°, D_outì€ ì¶œë ¥ ì°¨ì›ì´ë‹¤.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10  # ê°ê° ì°¨ë¡€ëŒ€ë¡œ ë°°ì¹˜ í¬ê¸°, D_in, H, D_out\n",
    "\n",
    "# ì…ë ¥ê³¼ ì¶œë ¥ì„ ì €ì¥í•˜ê¸° ìœ„í•´ ë¬´ì‘ìœ„ ê°’ì„ ê°–ëŠ” Tensorë¥¼ ìƒì„±í•œë‹¤.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# nn íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ìˆœì°¨ì  ê³„ì¸µ(sequence of layers)ë¡œ ì •ì˜í•œë‹¤.\n",
    "# nn.Sequentialì€ ë‹¤ë¥´ Moduleë“¤ì„ í¬í•¨í•˜ëŠ” Moduleë¡œ, ê·¸ Moduleë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì¶œë ¥ì„ ìƒì„±í•œë‹¤.\n",
    "# ê°ê°ì˜ Linear Moduleì€ ì„ í˜• í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì…ë ¥ìœ¼ë¡œë¶€í„° ì¶œë ¥ì„ ê³„ì‚°í•˜ê³ ,\n",
    "# ë‚´ë¶€ Tensorì— ê°€ì¤‘ì¹˜ì™€ í¸í–¥ì„ ì €ì¥í•œë‹¤.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# ë˜í•œ nn íŒ¨í‚¤ì§€ì—ëŠ” ë„ë¦¬ ì‚¬ìš©í•˜ëŠ” ì†ì‹¤ í•¨ìˆ˜ë“¤ì— ëŒ€í•œ ì •ì˜ë„ í¬í•¨í•˜ê³  ìˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” í‰ê·  ì œê³± ì˜¤ì°¨(MSE: Mean Squared Error)ë¥¼ ì†ì‹¤ í•¨ìˆ˜ë¡œ ì‚¬ìš©í•œë‹¤.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # ìˆœì „íŒŒ ë‹¨ê³„: ëª¨ë¸ì— xë¥¼ ì „ë‹¬í•˜ì—¬ ì˜ˆìƒë˜ëŠ” y ê°’ì„ ê³„ì‚°í•œë‹¤.\n",
    "    # Module ê°ì²´ëŠ” __call__ ì—°ì‚°ìë¥¼ ë®ì–´ì¨(Override) í•¨ìˆ˜ì²˜ëŸ¼ í˜¸ì¶œí•  ìˆ˜ ìˆê²Œ í•œë‹¤.\n",
    "    # ì´ë ‡ê²Œ í•¨ìœ¼ë¡œì¨ ì…ë ¥ ë°ì´í„°ì˜ Tensorë¥¼ Moduleì— ì „ë‹¬í•˜ì—¬ ì¶œë ¥ ë°ì´í„° Tensorë¥¼ ìƒì„±í•œë‹¤.\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # ì†ì‹¤ì„ ê³„ì‚°í•˜ê³  ì¶œë ¥í•œë‹¤. ì˜ˆì¸¡í•œ yì™€ ì •ë‹µì¸ yë¥¼ ê°–ëŠ” Tensorë“¤ì„ ì „ë‹¬í•˜ê³ , \n",
    "    # ì†ì‹¤ í•¨ìˆ˜ëŠ” ì†ì‹¤ ê°’ì„ ê°–ëŠ” Tensorë¥¼ ë°˜í™˜í•œë‹¤.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "        # ì—­ì „íŒŒ ë‹¨ê³„ë¥¼ ì‹¤í–‰í•˜ê¸° ì „ì— ë³€í™”ë„ë¥¼ 0ìœ¼ë¡œ ë§Œë“ ë‹¤.\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # ì—­ì „íŒŒ ë‹¨ê³„: ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ëª¨ë“  ë§¤ê°œë³€ìˆ˜ì— ëŒ€í•´ ì†ì‹¤ì˜ ë³€í™”ë„ë¥¼ ê³„ì‚°í•œë‹¤.\n",
    "        # ë‚´ë¶€ì ìœ¼ë¡œ ê° Moduleì˜ ë§¤ê°œë³€ìˆ˜ëŠ” requires_grad=True ì¼ ë•Œ, Tensor ë‚´ì— ì €ì¥ë˜ë¯€ë¡œ,\n",
    "        # ì´ í˜¸ì¶œì€ ëª¨ë“  ëª¨ë¸ì˜ ëª¨ë“  í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ê²Œ ëœë‹¤.\n",
    "        loss.backward()\n",
    "        \n",
    "        # ê²½ì‚¬í•˜ê°•ë²•(gradient descent)ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•œë‹¤.\n",
    "        # ê° ë§¤ê°œë³€ìˆ˜ëŠ” Tensorì´ë¯€ë¡œ ì´ì „ì— í–ˆë˜ ê²ƒê³¼ ê°™ì´ ë³€í™”ë„ì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤.\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"Conv2d\">Conv2d</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class <code>torch.nn.Conv2d()</code>\n",
    "\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stiride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button type=\"button\">Definition</button><br> Applies a 2D convolution over an input signal composed of several input planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—¬ëŸ¬ í‰ë©´ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ì…ë ¥ ì‹ í˜¸ì— 2D convolutionì„ ì ìš©í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in_channels (python:int) â€“ Number of channels in the input image\n",
    "\n",
    "* out_channels (python:int) â€“ Number of channels produced by the convolution\n",
    "\n",
    "* kernel_size (python:int or tuple) â€“ Size of the convolving kernel\n",
    "\n",
    "* stride (python:int or tuple, optional) â€“ Stride of the convolution. Default: 1\n",
    "\n",
    "* padding (python:int or tuple, optional) â€“ Zero-padding added to both sides of the input. Default: 0\n",
    "\n",
    "* padding_mode (string, optional) â€“ zeros\n",
    "\n",
    "* dilation (python:int or tuple, optional) â€“ Spacing between kernel elements. Default: 1\n",
    "\n",
    "* groups (python:int, optional) â€“ Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "* bias (bool, optional) â€“ If True, adds a learnable bias to the output. Default: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2)  # in_channels=16, out_channels=33, kernel_size(filter_size)=3,\n",
    "                                    # stride=2\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "\n",
    "# non-square kernels and unequal stride and with padding and dilation\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 28, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Q1. How to calculate the output size after Conv2d in PyTorch\n",
    "# https://discuss.pytorch.org/t/how-to-calculate-the-output-size-after-conv2d-in-pytorch/20405\n",
    "\n",
    "inputs = torch.rand(1, 1, 10, 10)\n",
    "mod = nn.Conv2d(1, 32, 3, 2, 1)\n",
    "out = mod(inputs)\n",
    "print(out.shape)  # ì–´ë–¤ ê°’ì´ ì¶œë ¥ë ê¹Œ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"Lienar\">Linear</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class<code>torch.nn.Linear(in_features, out_features, bias=True)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a linear transformation to the incoming data: y = xAT + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters<br>\n",
    "* in_features - size of each input sample\n",
    "* out_features - size of each output sample\n",
    "* bias - If set to False, the layer will not learn an additive bias. Default: <code>True</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape:  torch.Size([128, 20])\n",
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)  # in_features = 20, out_features = 30\n",
    "input = torch.randn(128, 20)\n",
    "print('input.shape: ', input.shape)\n",
    "output = m(input)\n",
    "print(output.size()) # ???!?!?!  -20.02.21.Fri pm 12:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ê²Œ ì™œ ì´í•´ê°€ ì•ˆê°€ì§€... ë­ì§€..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3035, -0.2441, -0.2721,  ...,  0.9307, -0.1898,  0.0967],\n",
      "        [-2.2034, -1.1245,  0.0411,  ...,  0.5764, -0.6538, -0.2309],\n",
      "        [-1.6404,  0.8272,  0.1735,  ...,  1.3595,  0.5311,  1.5078],\n",
      "        ...,\n",
      "        [-0.6212,  1.2815,  0.7916,  ...,  0.7449, -0.7889,  1.0028],\n",
      "        [ 0.3250,  0.0128, -0.5722,  ...,  1.5311,  0.2628, -1.1692],\n",
      "        [-1.0568,  0.1525,  0.4658,  ..., -0.6502, -0.3048, -1.1291]])\n"
     ]
    }
   ],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.3035)</td>\n",
       "      <td>tensor(-0.2441)</td>\n",
       "      <td>tensor(-0.2721)</td>\n",
       "      <td>tensor(1.8012)</td>\n",
       "      <td>tensor(1.9294)</td>\n",
       "      <td>tensor(2.4222)</td>\n",
       "      <td>tensor(1.5510)</td>\n",
       "      <td>tensor(-0.7361)</td>\n",
       "      <td>tensor(0.6903)</td>\n",
       "      <td>tensor(1.0940)</td>\n",
       "      <td>tensor(0.6094)</td>\n",
       "      <td>tensor(-1.0502)</td>\n",
       "      <td>tensor(0.9670)</td>\n",
       "      <td>tensor(1.1579)</td>\n",
       "      <td>tensor(0.7707)</td>\n",
       "      <td>tensor(0.5152)</td>\n",
       "      <td>tensor(0.2413)</td>\n",
       "      <td>tensor(0.9307)</td>\n",
       "      <td>tensor(-0.1898)</td>\n",
       "      <td>tensor(0.0967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(-2.2034)</td>\n",
       "      <td>tensor(-1.1245)</td>\n",
       "      <td>tensor(0.0411)</td>\n",
       "      <td>tensor(0.7757)</td>\n",
       "      <td>tensor(-0.8950)</td>\n",
       "      <td>tensor(-1.4705)</td>\n",
       "      <td>tensor(-2.1596)</td>\n",
       "      <td>tensor(-0.3662)</td>\n",
       "      <td>tensor(-1.1190)</td>\n",
       "      <td>tensor(1.0754)</td>\n",
       "      <td>tensor(-0.3060)</td>\n",
       "      <td>tensor(0.3282)</td>\n",
       "      <td>tensor(-0.7042)</td>\n",
       "      <td>tensor(-1.1023)</td>\n",
       "      <td>tensor(-0.5411)</td>\n",
       "      <td>tensor(0.8595)</td>\n",
       "      <td>tensor(-1.4358)</td>\n",
       "      <td>tensor(0.5764)</td>\n",
       "      <td>tensor(-0.6538)</td>\n",
       "      <td>tensor(-0.2309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(-1.6404)</td>\n",
       "      <td>tensor(0.8272)</td>\n",
       "      <td>tensor(0.1735)</td>\n",
       "      <td>tensor(0.4321)</td>\n",
       "      <td>tensor(-0.0466)</td>\n",
       "      <td>tensor(1.1273)</td>\n",
       "      <td>tensor(-0.6599)</td>\n",
       "      <td>tensor(-1.0778)</td>\n",
       "      <td>tensor(0.8083)</td>\n",
       "      <td>tensor(1.3652)</td>\n",
       "      <td>tensor(2.2923)</td>\n",
       "      <td>tensor(2.6808)</td>\n",
       "      <td>tensor(0.5248)</td>\n",
       "      <td>tensor(-0.4709)</td>\n",
       "      <td>tensor(-0.7522)</td>\n",
       "      <td>tensor(-1.1187)</td>\n",
       "      <td>tensor(-1.0345)</td>\n",
       "      <td>tensor(1.3595)</td>\n",
       "      <td>tensor(0.5311)</td>\n",
       "      <td>tensor(1.5078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(-1.6998)</td>\n",
       "      <td>tensor(1.4340)</td>\n",
       "      <td>tensor(-0.2018)</td>\n",
       "      <td>tensor(0.8807)</td>\n",
       "      <td>tensor(-0.4671)</td>\n",
       "      <td>tensor(-2.2015)</td>\n",
       "      <td>tensor(1.5113)</td>\n",
       "      <td>tensor(-1.2477)</td>\n",
       "      <td>tensor(0.7252)</td>\n",
       "      <td>tensor(-1.0329)</td>\n",
       "      <td>tensor(-0.9388)</td>\n",
       "      <td>tensor(0.5623)</td>\n",
       "      <td>tensor(-1.8487)</td>\n",
       "      <td>tensor(-1.1583)</td>\n",
       "      <td>tensor(-1.3891)</td>\n",
       "      <td>tensor(0.2192)</td>\n",
       "      <td>tensor(-0.3293)</td>\n",
       "      <td>tensor(0.3003)</td>\n",
       "      <td>tensor(0.9298)</td>\n",
       "      <td>tensor(0.8206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.5909)</td>\n",
       "      <td>tensor(-0.3114)</td>\n",
       "      <td>tensor(0.5571)</td>\n",
       "      <td>tensor(0.7769)</td>\n",
       "      <td>tensor(-0.2031)</td>\n",
       "      <td>tensor(-0.0492)</td>\n",
       "      <td>tensor(-1.9010)</td>\n",
       "      <td>tensor(-0.1413)</td>\n",
       "      <td>tensor(-0.9198)</td>\n",
       "      <td>tensor(-0.3160)</td>\n",
       "      <td>tensor(-1.6592)</td>\n",
       "      <td>tensor(-1.5972)</td>\n",
       "      <td>tensor(0.1778)</td>\n",
       "      <td>tensor(0.6365)</td>\n",
       "      <td>tensor(1.0252)</td>\n",
       "      <td>tensor(-1.0993)</td>\n",
       "      <td>tensor(-0.4021)</td>\n",
       "      <td>tensor(-1.6923)</td>\n",
       "      <td>tensor(1.6547)</td>\n",
       "      <td>tensor(0.4241)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                1                2               3  \\\n",
       "0   tensor(1.3035)  tensor(-0.2441)  tensor(-0.2721)  tensor(1.8012)   \n",
       "1  tensor(-2.2034)  tensor(-1.1245)   tensor(0.0411)  tensor(0.7757)   \n",
       "2  tensor(-1.6404)   tensor(0.8272)   tensor(0.1735)  tensor(0.4321)   \n",
       "3  tensor(-1.6998)   tensor(1.4340)  tensor(-0.2018)  tensor(0.8807)   \n",
       "4   tensor(0.5909)  tensor(-0.3114)   tensor(0.5571)  tensor(0.7769)   \n",
       "\n",
       "                 4                5                6                7  \\\n",
       "0   tensor(1.9294)   tensor(2.4222)   tensor(1.5510)  tensor(-0.7361)   \n",
       "1  tensor(-0.8950)  tensor(-1.4705)  tensor(-2.1596)  tensor(-0.3662)   \n",
       "2  tensor(-0.0466)   tensor(1.1273)  tensor(-0.6599)  tensor(-1.0778)   \n",
       "3  tensor(-0.4671)  tensor(-2.2015)   tensor(1.5113)  tensor(-1.2477)   \n",
       "4  tensor(-0.2031)  tensor(-0.0492)  tensor(-1.9010)  tensor(-0.1413)   \n",
       "\n",
       "                 8                9               10               11  \\\n",
       "0   tensor(0.6903)   tensor(1.0940)   tensor(0.6094)  tensor(-1.0502)   \n",
       "1  tensor(-1.1190)   tensor(1.0754)  tensor(-0.3060)   tensor(0.3282)   \n",
       "2   tensor(0.8083)   tensor(1.3652)   tensor(2.2923)   tensor(2.6808)   \n",
       "3   tensor(0.7252)  tensor(-1.0329)  tensor(-0.9388)   tensor(0.5623)   \n",
       "4  tensor(-0.9198)  tensor(-0.3160)  tensor(-1.6592)  tensor(-1.5972)   \n",
       "\n",
       "                12               13               14               15  \\\n",
       "0   tensor(0.9670)   tensor(1.1579)   tensor(0.7707)   tensor(0.5152)   \n",
       "1  tensor(-0.7042)  tensor(-1.1023)  tensor(-0.5411)   tensor(0.8595)   \n",
       "2   tensor(0.5248)  tensor(-0.4709)  tensor(-0.7522)  tensor(-1.1187)   \n",
       "3  tensor(-1.8487)  tensor(-1.1583)  tensor(-1.3891)   tensor(0.2192)   \n",
       "4   tensor(0.1778)   tensor(0.6365)   tensor(1.0252)  tensor(-1.0993)   \n",
       "\n",
       "                16               17               18               19  \n",
       "0   tensor(0.2413)   tensor(0.9307)  tensor(-0.1898)   tensor(0.0967)  \n",
       "1  tensor(-1.4358)   tensor(0.5764)  tensor(-0.6538)  tensor(-0.2309)  \n",
       "2  tensor(-1.0345)   tensor(1.3595)   tensor(0.5311)   tensor(1.5078)  \n",
       "3  tensor(-0.3293)   tensor(0.3003)   tensor(0.9298)   tensor(0.8206)  \n",
       "4  tensor(-0.4021)  tensor(-1.6923)   tensor(1.6547)   tensor(0.4241)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(input)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
