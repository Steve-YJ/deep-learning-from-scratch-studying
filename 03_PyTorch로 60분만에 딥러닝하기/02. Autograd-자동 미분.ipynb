{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Autograd-ìë™ë¯¸ë¶„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchì˜ ëª¨ë“  ì‹ ê²½ë§ì˜ ì¤‘ì‹¬ì—ëŠ” autograd íŒ¨í‚¤ì§€ê°€ ìˆë‹¤. ë¨¼ì € ì´ê²ƒì„ ê°€ë³ê²Œ ì‚´í´ë³¸ ë’¤, ì²«ë²ˆì§¸ ì‹ ê²½ë§ì„ í•™ìŠµì‹œì¼œë³´ê² ë‹¤.<br>(ì£¼ì˜! ê°€ë³ì§€ ì•Šì„ ìˆ˜ ìˆìŒğŸ˜‘)<br/>\n",
    "\n",
    "\n",
    "<code>autogradíŒ¨í‚¤ì§€</code>ëŠ” **Tensorì˜ ëª¨ë“  ì—°ì‚°ì— ëŒ€í•´ ìë™ ë¯¸ë¶„ì„ ì œê³µ**í•œë‹¤. ì´ëŠ” <code>ì‹¤í–‰-ê¸°ë°˜-ì •ì˜(define-by-run)í”„ë ˆì„ì›Œí¬</code>ë¡œ, ì½”ë“œë¥¼ ì–´ë–»ê²Œ ì‘ì„±í•˜ì—¬ ì‹¤í–‰í•˜ëŠëƒì— ë”°ë¼ ì—­ì „íŒŒê°€ ì •ì˜ëœë‹¤ëŠ” ëœ»ì´ë©°, ì—­ì „íŒŒëŠ” í•™ìŠµ ê³¼ì •ì˜ ë§¤ë‹¨ê³„ë§ˆë‹¤ ë‹¬ë¼ì§„ë‹¤.<br/>\n",
    "ğŸ˜ƒ ë” ê°„ë‹¨í•œ ìš©ì–´ë¡œ ëª‡ ê°€ì§€ ì˜ˆë¥¼ ì‚´í´ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ“**Note**<br/>\n",
    "\n",
    "<code>**Tensor í´ë˜ìŠ¤**</code><br/>\n",
    "\n",
    "*  íŒ¨í‚¤ì§€ì˜ ì¤‘ì‹¬ì—ëŠ” **torch.Tensor í´ë˜ìŠ¤**ê°€ ìˆë‹¤. ë§Œì•½ <code>.requires_grad</code>ì†ì„±ì„ Trueë¡œ ì„¤ì •í•˜ë©´, ê·¸ tensorì—ì„œ ì´ë¤„ì§„ ëª¨ë“  ì—°ì‚°ë“¤ì„ ì¶”ì (track)í•˜ê¸° ì‹œì‘í•œë‹¤.\n",
    "\n",
    "    * <code>.requires_grad=True</code> <- ë’¤ì—ì„œ ë§ì´ ë³´ê²Œ ë  ê²ƒì´ë‹¤.\n",
    "\n",
    "    ê³„ì‚°ì´ ì™„ë£Œëœ í›„ .backward()ë¥¼ í˜¸ì¶œí•˜ì—¬ ëª¨ë“  ë³€í™”ë„(gradient)ë¥¼ ìë™ìœ¼ë¡œ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤. ì´ Tensorì˜ ë³€í™”ë„ëŠ” .grad ì†ì„±ì— ëˆ„ì ëœë‹¤.\n",
    "\n",
    "*  Tensorê°€ ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒì„ ì¤‘ë‹¨í•˜ë ¤ë©´, <code>.detach()</code>ë¥¼ í˜¸ì¶œí•˜ì—¬ ì—°ì‚° ê¸°ë¡ìœ¼ë¡œë¶€í„° ë¶„ë¦¬(detach)í•˜ì—¬ ì´í›„ ì—°ì‚°ë“¤ì´ ì¶”ì ë˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. \n",
    "\n",
    "*  ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒê³¼ ë©”ëª¨ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•´, ì½”ë“œ ë¸”ëŸ­ì„ <code>with torch.no_grad():</code>ë¡œ ê°ìŒ€ ìˆ˜ ìˆë‹¤. íŠ¹íˆ ë³€í™”ë„(gradient)ëŠ” í•„ìš”ì—†ì§€ë§Œ, requires_grad=Trueê°€ ì„¤ì •ë˜ì–´ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°–ëŠ” ëª¨ë¸ì„ í‰ê°€(evaluate)í•  ë•Œ ìœ ìš©í•˜ë‹¤.\n",
    "\n",
    "<code>**Function í´ë˜ìŠ¤**</code><br/>\n",
    "\n",
    "*  Autograd êµ¬í˜„ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ ë” ìˆë‹¤. ë°”ë¡œ **<code>Function í´ë˜ìŠ¤<code>**ì´ë‹¤.\n",
    "\n",
    "*  Tensorì™€ Functionì€ ì„œë¡œ ì—°ê²°ë˜ì–´ ìˆìœ¼ë©°, ëª¨ë“  ì—°ì‚° ê³¼ì •ì„ ë¶€í˜¸í™”(encode)í•˜ì—¬ ìˆœí™˜í•˜ì§€ ì•ŠëŠ” ê·¸ë˜í”„(acyclic graph)ë¥¼ ìƒì„±í•œë‹¤. ê° tensorëŠ” <code>.grad_fnì†ì„±</code>ì„ ê°–ê³  ìˆëŠ”ë°, ì´ëŠ” Tensorë¥¼ ìƒì„±í•œ Functionì„ ì°¸ì¡°í•˜ê³  ìˆë‹¤.(ë‹¨, ì‚¬ìš©ìê°€ ë§Œë“  TensorëŠ” ì˜ˆì™¸ë¡œ, ì´ ë•Œ grad_fnì€ None)ì´ë‹¤.<br/>\n",
    "ğŸ¤¨ ì´ ë§ì€ ë„í†µ ì„¤ëª…ë§Œ ë“¤ì–´ì„œ ëª¨ë¥´ê² êµ°...\n",
    "\n",
    "*  ë„í•¨ìˆ˜ë¥¼ ê³„ì‚°í•˜ê¸° ìœ„í•´ì„œëŠ” Tensorì˜ .backward()ë¥¼ í˜¸ì¶œí•˜ë©´ ëœë‹¤. ë§Œì•½ Tensorê°€ ìŠ¤ì¹¼ë¼(scalar)ì¸ ê²½ìš°(ì˜ˆ. í•˜ë‚˜ì˜ ìš”ì†Œ ê°’ë§Œ ê°–ëŠ” ë“±) ì—ëŠ” ì¸ìë¥¼ ì •í•´ì¤„ í•„ìš”ê°€ ì—†ë‹¤. í•˜ì§€ë§Œ ì—¬ëŸ¬ ê°œì˜ ìš”ì†Œë¥¼ ê°–ê³  ìˆì„ ë•ŒëŠ” tensorì˜ ëª¨ì–‘ gradientì˜ ì¸ìë¡œ ì§€ì •í•  í•„ìš”ê°€ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial\n",
    "ğŸ‘¨ğŸ»â€ğŸ’» Tutorial Start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchë¥¼ ìƒì„±í•˜ê³  requires_grad=Trueë¥¼ ì„¤ì •í•˜ì—¬ ì—°ì‚°ì„ ê¸°ë¡í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorì— ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤. requires_grad=Trueë¥¼ ì„¤ì •í–ˆê¸° ë•Œë¬¸ì— ì—°ì‚°ì„ ê¸°ë¡í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yëŠ” ì—°ì‚°ì˜ ê²°ê³¼ë¡œ ìƒì„±ëœ ê²ƒì´ë¯€ë¡œ grad_fnì„ ê°–ëŠ”ë‹¤<br/>\n",
    "grad_fnì´ ìƒì„±ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x000002715E230988>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yì— ë‹¤ë¥¸ ì—°ì‚°ì„ ìˆ˜í–‰í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.requires_grad(...)</code> ë“±ì¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".requires_grad(...)ëŠ” ê¸°ì¡´ Tensorì˜ requires_grad ê°’ì„ ë°”ê¿”ì¹˜ê¸° (in-place)í•˜ì—¬ ë³€ê²½í•œë‹¤. ì…ë ¥ê°’ì´ ì§€ì •ë˜ì§€ ì•Šìœ¼ë©´ ê¸°ë³¸ê°’ì€ Falseì´ë‹¤.<br/>\n",
    "ğŸ¤·ğŸ»â€â™‚ï¸ ë­” ë§ì´ëƒ... 20.02.19.Wed pm4:43<br/>\n",
    "\n",
    "\n",
    "ì•„ë˜ì˜ ì˜ˆì œë¥¼ í†µí•´ ì‚´í´ë³´ì pm6:52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x000002715D599948>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2, 2)  # standard normal distribution (2, 2)\n",
    "a = ((a * 3) / (a - 1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤” Q1. requires_grad(...)í•¨ìˆ˜ê°€ Falseì¼ ë•Œì™€ Trueì¼ ë•Œ, ë¬´ì—‡ì´ ë‹¤ë¥¸ê±¸ê¹Œ?<br/>\n",
    "ğŸ¤” Q2. grad_fnì€ ë­”ê°€...?\n",
    "\n",
    "âœï¸ A1. requires_grad=Trueë¥¼ ì„¤ì •í•˜ë©´ ì—°ì‚°ì„ ê¸°ë¡í•  ìˆ˜ ìˆë‹¤. Trueì¼ ë•Œ, ì—°ì‚°ì„ ê¸°ë¡í•  ìˆ˜ ìˆë‹¤ë©´ Falseì¼ ë•ŒëŠ” ì—°ì‚°ì„ ê¸°ë¡í•  ìˆ˜ ì—†ë‹¤ëŠ” ê²ƒì´ê² ì§€!<br/>\n",
    "âœï¸ A2. requires_grad=Trueë¡œ ì„¤ì •í•œ ë³€ìˆ˜ë¡œ ë‹¤ë¥¸ ì—°ì‚°ì„ í•  ê²½ìš° ìƒì„±ë˜ëŠ” ê²ƒ ê°™ë‹¤.(í™•ì‹¤í•˜ì§€ëŠ” ì•Šë‹¤.)<br/>\n",
    "\n",
    "\n",
    "Reference<br/>\n",
    "https://pytorch.org/tutorials/beginner/former_torchies/autograd_tutorial.html\n",
    "\n",
    "**AUTOGRAD**<br/>\n",
    "Autograd is now core torch package for automatic differenciation. It uses a tape based system for automatic differenciation.<br/>\n",
    "In the forward phase, the autograd tape will remember all the operations it executed, and in the backward phase, it will replay the operations.<br/> \n",
    "Each variable has <code>a .grad_fn</code> attribute that references a function that has created a function (except for Tensors created by the user - these have None as .grad_fn).<br/>\n",
    "\n",
    "ë¶„ëª… í•œêµ­ì–´ë¥¼ ë” ì˜í•˜ëŠ”ë°... ì˜ì–´ë¡œ ë°›ì•„ë“¤ì´ëŠ”ê²Œ ë” ì˜ ì´í•´ê°€ ë˜ë‹¤ë‹ˆ...!<br/>\n",
    "\"ê° ë³€ìˆ˜ì—ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•œ í•¨ìˆ˜ë¥¼ ì°¸ì¡°í•˜ëŠ” .grad_fn ì†ì„±ì´ ìˆë‹¤.\"<br/>\n",
    "ê²°êµ­ ì´ê²ƒë„ forwardì™€ backwardì—ì„œ ê³„ì‚°ì„ ì¶”ì í•˜ê³  ê¸°ì–µí•˜ê¸° ìœ„í•¨ì´ ì•„ë‹ê¹Œ\n",
    "\n",
    "ê°ê°ì˜ ë³€ìˆ˜ë“¤ì€ .grad_fnë¼ëŠ” ì†ì„±ê°’ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ .grad_fnì€ í•¨ìˆ˜ë¥¼ ìƒì„±í•œ í•¨ìˆ˜ë¥¼ ì°¸ì¡°í•œë‹¤. ì¦‰ ê° ë³€ìˆ˜ì—ëŠ” í•¨ìˆ˜ë¥¼ ìƒì„±í•œ í•¨ìˆ˜ë¥¼ ì°¸ì¡°í•˜ëŠ” .grad_fn ì†ì„±ì´ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient(ë³€í™”ë„)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ì—­ì „íŒŒ(backprop)ì„ í•´ë³´ì. outì€ í•˜ë‚˜ì˜ ìŠ¤ì¹¼ë¼ ê°’ë§Œ ê°–ê³  ìˆê¸° ë•Œë¬¸ì—, out.backward()ëŠ” out.backward(torch.tensor(1.))ê³¼ ë™ì¼í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë³€í™”ë„ d(out)/dxë¥¼ ì¶œë ¥í•œë‹¤.<br/>\n",
    "í•´ì„:: xê°’ì´ ì•„ì£¼ ì¡°ê¸ˆ ì¦ê°€í–ˆì„ ë•Œì˜ ë³€í™”ëŸ‰. ì¦‰, ê¸°ìš¸ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤¨ ì•„... ì§€ë‚œë²ˆì— í–ˆì„ ë•Œ, ì—¬ê¸°ì„œ ë§‰í˜”ë˜ ê¸°ì–µì´...<br/>\n",
    "ğŸ˜ƒ ë°‘ëŸ¬ë‹1ì„ í•œ ë²ˆ ë…íŒŒí•˜ê³  ì™”ê¸°ì— íŒ¨ê¸°ìˆê²Œ ë°€ê³ ë‚˜ê°„ë‹¤ -20.02.19.wed pm7:10-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¼ë°˜ì ìœ¼ë¡œ, torch.autogradëŠ” ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì„ ê³„ì‚°í•˜ëŠ” ì—”ì§„ì´ë‹¤.(Jocobian Matrixë€ ìˆ˜í•™ì ìœ¼ë¡œ iì— ëŒ€í•œ yì˜ ë³€í™”ë„ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤.)<br/>\n",
    " ì¦‰, ì–´ë–¤ ë²¡í„° v=(v1v2â‹¯vm)T ì— ëŒ€í•´ vTâ‹…J ì„ ì—°ì‚°í•©ë‹ˆë‹¤. ë§Œì•½ v ê°€ ìŠ¤ì¹¼ë¼ í•¨ìˆ˜ l=g(yâƒ— ) ì˜ ê¸°ìš¸ê¸°ì¸ ê²½ìš°, v=(âˆ‚lâˆ‚y1â‹¯âˆ‚lâˆ‚ym)T ì´ë©°, **ì—°ì‡„ë²•ì¹™(chain rule)ì— ë”°ë¼ ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì€ xâƒ—  ì— ëŒ€í•œ l ì˜ ê¸°ìš¸ê¸°ê°€ ë©ë‹ˆë‹¤:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¤¨ ë§ì´ ì°¸ ì–´ë µì£ ?<br/>\n",
    "ğŸ˜ƒ ë°‘ëŸ¬ë‹ ìˆ˜ì¹˜ë¯¸ë¶„í¸ì„ ì°¸ê³ í•˜ì‹œë©´ ì¢‹ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì˜ ì´ëŸ¬í•œ íŠ¹ì„±ì€ ìŠ¤ì¹¼ë¼ê°€ ì•„ë‹Œ ì¶œë ¥ì„ ê°–ëŠ” ëª¨ë¸ì— ì™¸ë¶€ ë³€í™”ë„ë¥¼ ì œê³µ(feed)í•˜ëŠ” ê²ƒì„ ë§¤ìš° í¸ë¦¬í•˜ê²Œ í•´ì¤€ë‹¤. \n",
    "\n",
    "ì´ì œ ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì˜ ì˜ˆì œë¥¼ ì‚´í´ë³´ì."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([104.9465, 377.7879, 939.2187], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# torch x ì„ ì–¸\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ ê²½ìš° yëŠ” ë” ì´ìƒ ìŠ¤ì¹¼ë¼ ê°’ì´ ì•„ë‹ˆë‹¤. <code>torch.autograd</code>ëŠ” ì „ì²´ ì•¼ì½”ë¹„ì•ˆì„ ì§ì ‘ ê³„ì‚°í• ìˆ˜ëŠ” ì—†ì§€ë§Œ, ë²¡í„°-ì•¼ì½”ë¹„ì•ˆ ê³±ì€ ê°„ë‹¨íˆ <code>backward</code>ì— í•´ë‹¹ ë²¡í„°ë¥¼ ì¸ìë¡œ ì œê³µí•˜ì—¬ ì–»ì„ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([0.1, 1.0, 0.0001], dtype=torch.float)\n",
    "y.backward(v)\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë˜í•œ <code>with torch.no_grad():</code>ë¡œ ì½”ë“œ ë¸”ëŸ­ì„ ê°ì‹¸ì„œ autogradê°€ <code>.requires_grad=True</code>ì¸ Tensorë“¤ì˜ ì—°ì‚° ê¸°ë¡ì„ ì¶”ì í•˜ëŠ” ê²ƒì„ ë©ˆì¶œ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x ** 2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x ** 2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference:\n",
    "* í•œê¸€: https://tutorials.pytorch.kr/beginner/blitz/autograd_tutorial.html\n",
    "* ì˜ë¬¸: https://pytorch.org/tutorials/beginner/former_torchies/autograd_tutorial.html\n",
    "í•œê¸€íŒê³¼ ì˜ë¬¸íŒì˜ ë‚´ìš©ì´ ì¡°ê¸ˆ ë‹¤ë¥´ë‹¤... ì´ë˜ì„œ ì˜ì–´ë¥¼ í•´ì•¼í•œë‹¤ëŠ”...!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
