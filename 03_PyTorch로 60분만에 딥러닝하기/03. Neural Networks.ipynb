{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì‹ ê²½ë§\n",
    "\n",
    "Reference: https://tutorials.pytorch.kr/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹ ê²½ë§ì€ <code>torch.nn</code> íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒì„±í•  ìˆ˜ ìˆë‹¤.<br/>\n",
    "ì§€ê¸ˆê¹Œì§€ëŠ” <code>autograd</code>ë¥¼ ì‚´í´ë´¤ë‹¤. \n",
    "\n",
    "<code>nn</code>ì€ ëª¨ë¸ì„ ì •ì˜í•˜ê³  ë¯¸ë¶„í•˜ëŠ” ë° <code>autograd</code>ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
    "\n",
    "<code>nn.Module</code>ì€ ê³„ì¸µ(Layer)ê³¼ outputì„ ë°˜í™˜í•˜ëŠ” <code>forward(input)</code> ë©”ì„œë“œë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ˜„ ìš°ë¦¬ê°€ ì´ì „ ì¥ì—ì„œ ë°°ì› ë˜ <code>autograd</code>(ìë™ë¯¸ë¶„) íŒ¨í‚¤ì§€ê°€ <code>nn</code> ëª¨ë“ˆê³¼ ë§Œë‚˜ì„œ **ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€** ì•Œì•„ë³´ì<br>\n",
    "ğŸ˜„ ê·¸ë¦¬ê³  <code>nn</code>íŒ¨í‚¤ì§€ë„ ìƒ…ìƒ…íˆ íŒŒí—¤ì³ë³´ì!(Torch Packageë¥¼ ë‚±ë‚±ì´ íŒŒí—¤ì¹˜ê³ ì™”ë‹¤! ì´ì œ í•™ìŠµë§Œ ì˜ í•˜ë©´ ëœë‹¤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ëŠ˜ì˜ ì˜ˆì œëŠ” ìˆ«ì ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‹ ê²½ë§ì´ë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./LeNet-5 Architecture.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeNet-5 Architecture as Published in the original paper<a href=\"http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference:\n",
    "\n",
    "https://medium.com/@pechyonkin/key-deep-learning-architectures-lenet-5-6fc3c59e6f4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ìœ„ì— ë³´ì´ëŠ” LeNetì€ ê°„ë‹¨í•œ ìˆœì „íŒŒ ë„¤íŠ¸ì›Œí¬(Feed-forward network)ì´ë‹¤.\n",
    "\n",
    "ì…ë ¥(input)ì„ ë°›ì•„ ì—¬ëŸ¬ ê³„ì¸µì— ì°¨ë¡€ë¡œ ì „ë‹¬í•œ í›„, ìµœì¢… ì¶œë ¥(output)ì„ ì œê³µí•œë‹¤.\n",
    "\n",
    "ì‹ ê²½ë§ì˜ ì¼ë°˜ì ì¸ í•™ìŠµê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.<br/>\n",
    "* í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œ ë³€ìˆ˜(ë˜ëŠ” ê°€ì¤‘ì¹˜(weight)ë¥¼ ê°–ëŠ” ì‹ ê²½ë§ì„ ì •ì˜í•œë‹¤.\n",
    "* ë°ì´í„°ì…‹(dataset)ì…ë ¥ì„ ë°˜ë³µí•œë‹¤.\n",
    "* ì…ë ¥ì„ ì‹ ê²½ë§ì—ì„œ ì „íŒŒ(process)í•œë‹¤.\n",
    "* ì†ì‹¤(loss: ì¶œë ¥ì´ ì •ë‹µìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë–¨ì–´ì ¸ ìˆëŠ”ì§€)ì„ ê³„ì‚°í•œë‹¤.\n",
    "* ë³€í™”ë„(gradient)ë¥¼ ì‹ ê²½ë§ì˜ ë§¤ê°œë³€ìˆ˜ë“¤ì— ì—­ìœ¼ë¡œ ì „íŒŒí•œë‹¤. (Backpropagation)\n",
    "* ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒê³¼ ê°™ì€ ê°„ë‹¨í•œ ê·œì¹™ì„ ì‚¬ìš©í•œë‹¤.<br/>\n",
    "<code>ì—…ë°ì´íŠ¸ëœ ê°€ì¤‘ì¹˜(weight) = ê°€ì¤‘ì¹˜(weight) - í•™ìŠµë¥ (learning rate) * ë³€í™”ë„(gradient)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "W1 = W0 - Î·*(df/dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #1. ì‹ ê²½ë§ ì •ì˜í•˜ê¸°\n",
    "ì´ì œ ë³¸ê²©ì ìœ¼ë¡œ ì‹ ê²½ë§ì„ ì •ì˜í•´ë³´ë„ë¡ í•˜ì<br/>\n",
    "**ğŸš¨ì£¼ì„ì˜ Question(Q)ì„ ì£¼ëª©í•´ë³´ì!!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module): # nn.Module ëª¨ë“  ì‹ ê²½ë§ ëª¨ë“ˆì˜ ê¸°ë³¸ì´ ë˜ëŠ” í´ë˜ìŠ¤ì´ë‹¤.\n",
    "                      # ê° ì¸µ(Layer)ê³¼ í•¨ìˆ˜(Function)ë“± ì‹ ê²½ë§ì˜ êµ¬ì„±ìš”ì†Œë¥¼ ì´ í´ë˜ìŠ¤ ì•ˆì—ì„œ ì •ì˜í•œë‹¤.\n",
    "                      # ì •ë¦¬ - nn.Moduleì€ ëª¨ë“  ì‹ ê²½ë§ ëª¨ë“ˆì˜ ê¸°ë³¸ì´ ë˜ëŠ” í´ë˜ìŠ¤ë¡œ ë ˆì´ì–´, í•¨ìˆ˜ë“±ì„ ì •ì˜í•˜ëŠ”êµ¬ë‚˜!\n",
    "        \n",
    "    def __init__(self):  # ì´ˆê¸°í™” í•¨ìˆ˜   \n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution kernel\n",
    "        # (kernelê³¼ filterëŠ” ê°™ë‹¤) ì¦‰, filter sizeëŠ” 3x3\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3)  # ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, í•„í„°ì˜ í¬ê¸°\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3) # ë§ˆì°¬ê°€ì§€ ì…ë ¥ ì±„ë„ ìˆ˜, ì¶œë ¥ ì±„ë„ ìˆ˜, í•„í„°ì˜ í¬ê¸°    \n",
    "\n",
    "        # an affine operation: y = Wx + b\n",
    "        # input_imageì˜ dimensionì„ 6x6ì´ë¼ê³  ê°€ì •í•˜ì\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # Q1. ë§¤ê°œë³€ìˆ˜ ê°’ì€ ì–´ë–»ê²Œ ê³„ì‚°í•´ì•¼í• ê¹Œ?\n",
    "                                               # 6*6 from image dimension? -20.02.20.Thur pm 2:00-\n",
    "                                               # image dimensionì€ ì–´ë–»ê²Œ êµ¬í•˜ì§€? -20.02.20.Thur pm 8:05-\n",
    "                                               # https://discuss.pytorch.org/t/linear-layer-input-neurons-number-calculation-after-conv2d/28659\n",
    "                                               # Set the number of in_features for the first linear layer to (outputchanel * size of image)\n",
    "                                               # ë”°ë¼ì„œ nn.Linear()ì˜ ì²« ë²ˆì§¸ ì¸ì ê°’ì€ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆë‹¤.\n",
    "                                               # in_features = (output_chanel_num * height * width)\n",
    "                                               \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)  # í•„í„°ê°€ ì •ë°©í–‰ë ¬ì¸ ê²½ìš°, í•˜ë‚˜ì˜ ê°’ì„ ì¸ìë¡œ ì œê³µí•  ìˆ˜ ìˆë‹¤.\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "        \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "# Affine Operationì—ì„œ Linear ê³„ì¸µì˜ ë§¤ê°œë³€ìˆ˜ëŠ” ì–´ë–»ê²Œ ì •í•´ì§€ëŠ”ê±´ê°€? -20.02.20.Thur pm 7:49\n",
    "# ì—¬ì „íˆ ë¯¸ìŠ¤í…Œë¦¬ë‹¤(20.02.21.Fri.pm 12:22)... Torch Docì„ ë’¤ì ¸ë³´ì\n",
    "# nn.Linear()í•¨ìˆ˜ì˜ ì²« ë²—ì§¸ ì¸ìì—ëŠ” input sampleì˜ sizeê°€ ë“¤ì–´ê°„ë‹¤.\n",
    "# ë‘ ë²ˆì§¸ ì¸ìì—ëŠ” output sampleì˜ sizeê°€ ë“¤ì–´ê°„ë‹¤.\n",
    "# clas:: torch.nn.Linear(in_features, out_features, bias=True)\n",
    "# ë³¸ ì˜ˆì œì—ì„œëŠ” ì²« ì¸ìë¡œ 16 * 6 * 6ì˜ ê°’ì„ ì¸ìë¡œ ë°›ëŠ”ë° \n",
    "# ì´ëŠ” Conv2 ê³„ì¸µì„ ì§€ë‚œ ì¶œë ¥ ì±„ë„ì˜ ìˆ˜ê°€ 16, input_imageì˜ dimensionì´ 6*6ì´ê¸° ë•Œë¬¸ì´ë‹¤.\n",
    "# ì •ë¦¬í•˜ë©´ self1.fc1 = nn.Linear(16 * 6 * 6, 120)ì´ ëœë‹¤.\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>forward</code>í•¨ìˆ˜ë§Œ ì •ì˜í•˜ê³  ë‚˜ë©´, (ë³€í™”ë„ë¥¼ ê³„ì‚°í•˜ëŠ”) <code>backward</code>í•¨ìˆ˜ëŠ” <code>autograd</code>ë¥¼ ì‚¬ìš©í•˜ì—¬ ìë™ìœ¼ë¡œ ì •ì˜ëœë‹¤. <code>forward</code>í•¨ìˆ˜ì—ì„œëŠ” ì–´ë– í•œ Tensor ì—°ì‚°ì„ ì‚¬ìš©í•´ë„ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ì˜ í•™ìŠµ ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ë“¤ì€ <code>net.parameters()</code>ì— ì˜í•´ ë°˜í™˜ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())  # conv1's.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x0000021CA8757DC8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì„ì˜ì˜ 32x32 ì…ë ¥ê°’ì„ ë„£ì–´ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**<br>\n",
    "ì´ ì‹ ê²½ë§(LeNet)ì˜ ì˜ˆìƒë˜ëŠ” ì…ë ¥ í¬ê¸°ëŠ” 32x32ì´ë‹¤. ì´ ì‹ ê²½ë§ì— MNIST ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ”, ë°ì´í„°ì…‹ì˜ ì´ë¯¸ì§€ í¬ê¸°ë¥¼ 32x32ë¡œ ë³€ê²½í•´ì•¼ í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0120,  0.0656,  0.0773, -0.0016, -0.0734, -0.1500, -0.0617,  0.1941,\n",
      "         -0.0681,  0.0739]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë“  ë§¤ê°œë³€ìˆ˜ì˜ ë³€í™”ë„ ë²„í¼(gradient buffer)ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ê³ , ë¬´ì‘ìœ„ ê°’ìœ¼ë¡œ ì—­ì „íŒŒë¥¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê³„ì† ì§„í–‰í•˜ê¸° ì „ì—, ì§€ê¸ˆê¹Œì§€ ì‚´í´ë´¤ë˜ ê²ƒë“¤ì„ ë‹¤ì‹œ í•œë²ˆ ìš”ì•½í•´ë³´ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ìš”ì•½**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <code>torch.Tensor</code> - <code>backward()</code>ì™€ ê°™ì€ autograd ì—°ì‚°ì„ ì§€ì›í•˜ëŠ” ë‹¤ì°¨ì› ë°°ì—´ì´ë‹¤. ë˜í•œ tensorì— ëŒ€í•œ ë³€í™”ë„(gradient)ë¥¼ ê°–ê³  ìˆë‹¤.\n",
    "\n",
    "* <code>nn.Module</code> - ì‹ ê²½ë§ ëª¨ë“ˆ. ë§¤ê°œë³€ìˆ˜ë¥¼ ìº¡ìŠí™”(encapsulation)í•˜ëŠ” ê°„í¸í•œ ë°©ë²•ìœ¼ë¡œ, GPUë¡œ ì´ë™, ë‚´ë³´ë‚´ê¸°(exporting), ë¶ˆëŸ¬ì˜¤ê¸°(loading)ë“±ì˜ ì‘ì—…ì„ ìœ„í•œ í—¬í¼(helper)ë¥¼ ì œê³µí•œë‹¤.\n",
    "\n",
    "* <code>nn.Parameter</code> - Tensorì˜ í•œ ì¢…ë¥˜ë¡œ, <code>Module</code>ì— ì†ì„±ìœ¼ë¡œ í• ë‹¹ë  ë•Œ ìë™ìœ¼ë¡œ ë§¤ê°œë³€ìˆ˜ë¡œ ë“±ë¡ëœë‹¤.\n",
    "\n",
    "* <code>autograd.Function</code> - autograd ì—°ì‚°ì˜ ì „ë°©í–¥ê³¼ ì—­ë°©í–¥ì •ì˜ë¥¼ êµ¬í˜„í•œë‹¤. ëª¨ë“  <code>Tensor</code>ì—°ì‚°ì€ í•˜ë‚˜ ì´ìƒì˜ <code>Function</code>ë…¸ë“œë¥¼ ìƒì„±í•˜ë©°, ê° ë…¸ë“œëŠ” <code>Tensor</code>ë¥¼ ìƒì„±í•˜ê³  ì´ë ¥(history)ì„ ë¶€í˜¸í™” í•˜ëŠ” í•¨ìˆ˜ë“¤ê³¼ ì—°ê²°í•˜ê³  ìˆë‹¤.\n",
    "\n",
    "ğŸ‘‰ğŸ» ëª¨ë“  Tensor ì—°ì‚°ì€ ì ì–´ë„ í•˜ë‚˜ì˜ Function nodeë¥¼ ìƒì„±í•˜ëŠ”ë° Function NodeëŠ” í…ì„œë¥¼ ìƒì„±í•œ í•¨ìˆ˜ì™€ ì—°ê²°ëœë‹¤.<br/>\n",
    "ğŸ‘‰ğŸ» autograd packageë¥¼ ì‚¬ìš©í•´ì„œ ì§ì ‘ í™•ì¸í•´ë³¸ë‹¤ë©´ ë³´ë‹¤ ì§ê´€ì ìœ¼ë¡œ ì´í•´í•  ìˆ˜ ìˆê²Œ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì§€ê¸ˆê¹Œì§€ ë°°ìš´ ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤**\n",
    "* ì‹ ê²½ë§ì„ ì •ì˜í•˜ëŠ” ê²ƒ\n",
    "* ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  <code>backward</code>ë¥¼ í˜¸ì¶œí•˜ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ë” ì‚´í´ë³¼ë‚´ìš©ë“¤ì€ ë‹¤ìŒê³¼ ê°™ë‹¤**\n",
    "* ì†ì‹¤ì„ ê³„ì‚°í•˜ëŠ” ê²ƒ\n",
    "* ì‹ ê²½ë§ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°±ì‹ í•˜ëŠ” ê²ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #2. ì†ì‹¤ í•¨ìˆ˜(Loss Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘¨ğŸ»â€ğŸ« ì†ì‹¤í•¨ìˆ˜ë€ \n",
    "\n",
    "ì†ì‹¤ í•¨ìˆ˜ëŠ”(output, target)ì„ í•œ ìŒ(pair)ì˜ ì…ë ¥ìœ¼ë¡œ ë°›ì•„, ì¶œë ¥(output)ì´ ì •ë‹µ(target)ìœ¼ë¡œë¶€í„° ì–¼ë§ˆë‚˜ ë©€ë¦¬ ë–¨ì–´ì ¸ ìˆëŠ”ì§€ ì¶”ì •í•˜ëŠ” ê°’ì„ ê³„ì‚°í•œë‹¤.\n",
    "\n",
    "nníŒ¨í‚¤ì§€ì—ëŠ” ì—¬ëŸ¬ê°€ì§€ì˜ <code>ì†ì‹¤í•¨ìˆ˜</code>ë“¤ì´ ì¡´ì¬í•œë‹¤. ê°„ë‹¨í•œ ì†ì‹¤ í•¨ìˆ˜ë¡œëŠ” ì¶œë ¥ê³¼ ëŒ€ìƒê°„ì˜ í‰ê· ì œê³±ì˜¤ì°¨(mean-sqaured error)ë¥¼ ê³„ì‚°í•˜ëŠ” <code>nn.MSEloss</code>ê°€ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE ì˜ˆì‹œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0120,  0.0656,  0.0773, -0.0016, -0.0734, -0.1500, -0.0617,  0.1941,\n",
       "         -0.0681,  0.0739]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(input)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9448, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# example of MSE\n",
    "output = net(input)\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "                          # ì˜ˆì œë¥¼ ìœ„í•œ ë”ë¯¸ íƒ€ê²Ÿê°’ í• ë‹¹\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "                             # outì˜ shapeì´ 1,10ì´ì—ˆìœ¼ë‹ˆ targetì˜ shapeì„ ë§ì¶°ì¤€ë‹¤.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "loss = criterion(output, target)\n",
    "print('loss:', loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ <code>.grad_fn</code>ì†ì„±ì„ ì‚¬ìš©í•˜ì—¬ <code>loss</code>ë¥¼ ì—­ë°©í–¥ì—ì„œ ë”°ë¼ê°€ë‹¤ë³´ë©´, ì´ëŸ¬í•œ ëª¨ìŠµì˜ ì—°ì‚° ê·¸ë˜í”„ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ë”°ë¼ì„œ <code>loss.backward()</code>ë¥¼ ì‹¤í–‰í•  ë•Œ, ì „ì²´ ê·¸ë˜í”„ëŠ” ì†ì‹¤(loss)ì— ëŒ€í•˜ì—¬ ë¯¸ë¶„ë˜ë©°, ê·¸ë˜í”„ ë‚´ì˜ <code>requires_grad=True</code>ì¸ ëª¨ë“  TensorëŠ” ë³€í™”ë„(gradient)ê°€ ëˆ„ì ëœ <code>.grad</code>Tensorë¥¼ ê°–ê²Œ ëœë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000021CB08FDA48>\n",
      "<AddmmBackward object at 0x0000021CB0925AC8>\n",
      "<AccumulateGrad object at 0x0000021CAF2617C8>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSE Loss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #3. ì—­ì „íŒŒ(Backpropagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì˜¤ì°¨(Error)ë¥¼ ì—­ì „íŒŒí•˜ê¸° ìœ„í•´ì„œëŠ” <code>loss.backward()</code>ë§Œ í•´ì£¼ë©´ ëœë‹¤. ê¸°ì¡´ ë³€í™”ë„ë¥¼ ì—†ì• ëŠ” ì‘ì—…ì´ í•„ìš”í•œë°, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ë³€í™”ë„ê°€ ê¸°ì¡´ì˜ ê²ƒì— ëˆ„ì ë˜ê¸° ë•Œë¬¸ì´ë‹¤.\n",
    "\n",
    "ì´ì œ <code>loss.backward()</code>ë¥¼ í˜¸ì¶œí•˜ì—¬ ì—­ì „íŒŒ ì „ê³¼ í›„ì— conv1ì˜ bias gradientë¥¼ ì‚´í´ë³´ì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "conv1.bias.grad before backward\n",
      "tensor([ 0.0018, -0.0029,  0.0151,  0.0080, -0.0060, -0.0012])\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()  # zeroes the gradient buffers of all parameters\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## #4. ê°€ì¤‘ì¹˜ ê°±ì‹ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹¤ì œë¡œ ë§ì´ ì‚¬ìš©ë˜ëŠ” ê°€ì¥ ë‹¨ìˆœí•œ ê°±ì‹  ê·œì¹™ì€ í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•(SGD: Stochastic Gradient Descent)ì´ë‹¤.\n",
    "<code>ê°€ì¤‘ì¹˜(weight) = ê°€ì¤‘ì¹˜(weight) - í•™ìŠµë¥ (learning rate) * ë³€í™”ë„(gradient)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì‹ ê²½ë§ì„ êµ¬ì„±í•  ë•Œ, SGD, Nesterov-SGD, Adam, RMSProp ë“±ê³¼ ê°™ì€ ë‹¤ì–‘í•œ ê°±ì‹  ê·œì¹ ì„ ì‚¬ìš©í•˜ê³  ì‹¶ì„ ë•Œê°€ ìˆë‹¤. ì´ë¥¼ ìœ„í•´ì„œ <code>torch.optim</code>ë¼ëŠ” ì‘ì€ íŒ¨í‚¤ì§€ì— ì´ëŸ¬í•œ ë°©ë²•ë“¤ì„ ëª¨ë‘ êµ¬í˜„í•´ë‘ì—ˆë‹¤. ì‚¬ìš©ë²•ì€ ë§¤ìš° ê°„ë‹¨í•˜ë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Optimizerë¥¼ ìƒì„±í•œë‹¤.\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# í•™ìŠµ ê³¼ì •(training loop)ì—ì„œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n",
    "optimizer.zero_grad()  # zero the gradient buffers\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()  # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ì˜ì–´ìë£Œ: https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ## Future Work ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Review\n",
    "\n",
    "2. Back to PyTorch Introduction Book\n",
    "\n",
    "20.02.21.Sat pm 10:53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
